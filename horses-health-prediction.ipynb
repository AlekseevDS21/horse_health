{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8ac64-24c7-424e-9e70-8f7af0212824",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-15T19:16:36.597139Z",
     "iopub.status.busy": "2024-04-15T19:16:36.596770Z",
     "iopub.status.idle": "2024-04-15T19:16:37.322536Z",
     "shell.execute_reply": "2024-04-15T19:16:37.321568Z"
    },
    "papermill": {
     "duration": 0.739404,
     "end_time": "2024-04-15T19:16:37.324860",
     "exception": false,
     "start_time": "2024-04-15T19:16:36.585456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.ensemble import (\n",
    "    HistGradientBoostingClassifier, \n",
    "    GradientBoostingClassifier, \n",
    "    AdaBoostClassifier,  \n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,  \n",
    "    VotingClassifier,  \n",
    "    StackingClassifier,\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "from lightgbm import LGBMClassifier \n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "train = pd.read_csv(r\"/kaggle/input/playground-series-s3e22/train.csv\")\n",
    "test = pd.read_csv(r\"/kaggle/input/playground-series-s3e22/test.csv\")\n",
    "origin = pd.read_csv(r\"/kaggle/input/horse-survival-dataset/horse.csv\")\n",
    "\n",
    "num_var = [column for column in train.columns if train[column].nunique() > 10]\n",
    "bin_var = [column for column in train.columns if train[column].nunique() == 2]\n",
    "cat_var = ['temp_of_extremities', 'peripheral_pulse', 'mucous_membrane', 'capillary_refill_time', 'pain',\n",
    "           'peristalsis', 'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', 'rectal_exam_feces',\n",
    "           'abdomen', 'abdomo_appearance', 'lesion_2', 'surgery', 'age', 'surgical_lesion', 'lesion_3', 'cp_data']\n",
    "\n",
    "target = 'outcome'\n",
    "train[\"is_generated\"] = 1\n",
    "test[\"is_generated\"] = 1\n",
    "origin[\"is_generated\"] = 0\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "\n",
    "train_total = pd.concat([train, origin], ignore_index=True)\n",
    "\n",
    "train_total.drop_duplicates(inplace=True)\n",
    "total = pd.concat([train_total, test], ignore_index=True)\n",
    "\n",
    "def chi_squared_test(df, input_var, target_var, significance_level=0.05):\n",
    "    contingency_table = pd.crosstab(df[input_var], df[target_var])\n",
    "    chi2, p, _, _ = stats.chi2_contingency(contingency_table)\n",
    "    \n",
    "    if p < significance_level:\n",
    "        print(f'\\033[32m{input_var} has a significant relationship with the target variable.\\033[0m') \n",
    "    else:\n",
    "        print(f'\\033[31m{input_var} does not have a significant relationship with the target variable.\\033[0m')  \n",
    "\n",
    "for i in cat_var:\n",
    "    chi_squared_test(train, i, target)\n",
    "\n",
    "total[target] = total[target].map({'died':0,'euthanized':1,'lived':2})\n",
    "\n",
    "def preprocessing(df, le_cols, ohe_cols):\n",
    "    le = LabelEncoder()    \n",
    "    for col in le_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    df = pd.get_dummies(df, columns = ohe_cols)\n",
    "    \n",
    "    df[\"pain\"] = df[\"pain\"].replace('slight', 'moderate')\n",
    "    df[\"peristalsis\"] = df[\"peristalsis\"].replace('distend_small', 'normal')\n",
    "    df[\"rectal_exam_feces\"] = df[\"rectal_exam_feces\"].replace('serosanguious', 'absent')\n",
    "    df[\"nasogastric_reflux\"] = df[\"nasogastric_reflux\"].replace('slight', 'none')\n",
    "        \n",
    "    df[\"temp_of_extremities\"] = df[\"temp_of_extremities\"].fillna(\"normal\").map({'cold': 0, 'cool': 1, 'normal': 2, 'warm': 3})\n",
    "    df[\"peripheral_pulse\"] = df[\"peripheral_pulse\"].fillna(\"normal\").map({'absent': 0, 'reduced': 1, 'normal': 2, 'increased': 3})\n",
    "    df[\"capillary_refill_time\"] = df[\"capillary_refill_time\"].fillna(\"3\").map({'less_3_sec': 0, '3': 1, 'more_3_sec': 2})\n",
    "    df[\"pain\"] = df[\"pain\"].fillna(\"depressed\").map({'alert': 0, 'depressed': 1, 'moderate': 2, 'mild_pain': 3, 'severe_pain': 4, 'extreme_pain': 5})\n",
    "    df[\"peristalsis\"] = df[\"peristalsis\"].fillna(\"hypomotile\").map({'hypermotile': 0, 'normal': 1, 'hypomotile': 2, 'absent': 3})\n",
    "    df[\"abdominal_distention\"] = df[\"abdominal_distention\"].fillna(\"none\").map({'none': 0, 'slight': 1, 'moderate': 2, 'severe': 3})\n",
    "    df[\"nasogastric_tube\"] = df[\"nasogastric_tube\"].fillna(\"none\").map({'none': 0, 'slight': 1, 'significant': 2})\n",
    "    df[\"nasogastric_reflux\"] = df[\"nasogastric_reflux\"].fillna(\"none\").map({'less_1_liter': 0, 'none': 1, 'more_1_liter': 2})\n",
    "    df[\"rectal_exam_feces\"] = df[\"rectal_exam_feces\"].fillna(\"absent\").map({'absent': 0, 'decreased': 1, 'normal': 2, 'increased': 3})\n",
    "    df[\"abdomen\"] = df[\"abdomen\"].fillna(\"distend_small\").map({'normal': 0, 'other': 1, 'firm': 2,'distend_small': 3, 'distend_large': 4})\n",
    "    df[\"abdomo_appearance\"] = df[\"abdomo_appearance\"].fillna(\"serosanguious\").map({'clear': 0, 'cloudy': 1, 'serosanguious': 2})\n",
    "\n",
    "    return df    \n",
    "\n",
    "total = preprocessing(total, le_cols = [\"surgery\", \"age\", \"surgical_lesion\", \"cp_data\"], ohe_cols = [\"mucous_membrane\"])\n",
    "\n",
    "def features_engineering(df):   \n",
    "    data_preprocessed = df.copy()\n",
    "    cols_with_nan = df.drop(target,axis=1).columns[df.drop(target,axis=1).isna().any()].tolist()\n",
    "    for feature in cols_with_nan:\n",
    "        data_preprocessed[feature].fillna(data_preprocessed[feature].mode()[0], inplace=True)\n",
    "    return data_preprocessed\n",
    "\n",
    "total = features_engineering(total)\n",
    "\n",
    "df_train = total[total[target].notna()]\n",
    "df_test = total[total[target].isna()]\n",
    "df_test.drop(target,axis=1,inplace=True)\n",
    "\n",
    "full_features = df_test.columns.tolist()\n",
    "bin_features = df_test.select_dtypes('bool').columns\n",
    "\n",
    "df_train[bin_features] = df_train[bin_features].astype('int64')\n",
    "df_test[bin_features] = df_test[bin_features].astype('int64')\n",
    "\n",
    "def caculate_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average = 'micro')\n",
    "\n",
    "lgbm_baseline = LGBMClassifier(n_estimators=80,\n",
    "                     max_depth=4,\n",
    "                     random_state=42)\n",
    "\n",
    "f1_results = pd.DataFrame(columns=['Selected_Features', 'F1'])\n",
    "\n",
    "def evaluation(df, select_features, note):\n",
    "    global f1_results\n",
    "    \n",
    "    X = df[select_features]\n",
    "    Y = df[target]\n",
    "    \n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "        lgbm_baseline.fit(X_train, y_train)\n",
    "        y_hat = lgbm_baseline.predict(X_test) \n",
    "        f1 = caculate_f1(y_test, y_hat)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    average_f1 = np.mean(f1_scores)\n",
    "    new_row = {'Selected_Features': note, 'F1': average_f1}\n",
    "    f1_results = pd.concat([f1_results, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    return average_f1\n",
    "    \n",
    "evaluation(df=df_train,select_features=full_features,note='Baseline')\n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  \n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) >= threshold: \n",
    "                colname = corr_matrix.columns[i]                  \n",
    "                col_corr.add(colname)\n",
    "    return col_corr      \n",
    "\n",
    "corr_features = correlation(df_train, 0.35)\n",
    "corr_features\n",
    "\n",
    "corr_features = df_test.drop(['abdominal_distention',\n",
    " 'abdomo_protein',\n",
    " 'capillary_refill_time',\n",
    " 'cp_data',\n",
    " 'lesion_3',\n",
    " 'mucous_membrane_dark_cyanotic',\n",
    " 'mucous_membrane_normal_pink',\n",
    " 'packed_cell_volume',\n",
    " 'peripheral_pulse',\n",
    " 'peristalsis',\n",
    " 'rectal_exam_feces',\n",
    " 'respiratory_rate',\n",
    " 'surgical_lesion',\n",
    " 'temp_of_extremities',\n",
    " 'total_protein'],axis=1).columns.tolist()\n",
    "\n",
    "evaluation(df=df_train,select_features=corr_features,note='Corr Features')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def f_importance_plot(f_imp):\n",
    "    fig = plt.figure(figsize=(12, 0.20*len(f_imp)))\n",
    "    plt.title(f'Feature importances', size=16, y=1.05, \n",
    "              fontweight='bold')\n",
    "    a = sns.barplot(data=f_imp, x='imp', y='feature', linestyle=\"-\", \n",
    "                    linewidth=0.5, edgecolor=\"black\",palette='GnBu')\n",
    "    plt.xlabel('')\n",
    "    plt.xticks([])\n",
    "    plt.ylabel('')\n",
    "    plt.yticks(size=11)\n",
    "    \n",
    "    for j in ['right', 'top', 'bottom']:\n",
    "        a.spines[j].set_visible(False)\n",
    "    for j in ['left']:\n",
    "        a.spines[j].set_linewidth(0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "clf = LGBMClassifier(n_estimators=1000,\n",
    "                     max_depth=10,\n",
    "                     random_state=42)\n",
    "clf.fit(df_train.drop(target,axis=1), df_train[target])\n",
    "\n",
    "f_imp_df = pd.DataFrame({'feature': df_train.drop(target,axis=1).columns, 'imp': clf.feature_importances_})\n",
    "f_imp_df.sort_values(by='imp',ascending=False,inplace=True)\n",
    "f_importance_plot(f_imp_df)\n",
    "\n",
    "best_feature_num = 30\n",
    "best_score = 0.7392406127690802\n",
    "print(f'Best feature number is Top {best_feature_num}, Best score is {best_score}')\n",
    "\n",
    "best_features = f_imp_df.head(best_feature_num).feature.to_list()\n",
    "\n",
    "X = df_train[best_features]\n",
    "y = df_train[target]\n",
    "\n",
    "test_df = df_test[best_features]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "hist_model = HistGradientBoostingClassifier(\n",
    "    max_depth=4,           # Adjust the maximum depth of each tree\n",
    "    max_iter=80,          # Adjust the number of boosting iterations\n",
    "    learning_rate=0.1,     # Adjust the learning rate\n",
    "    random_state=42,   \n",
    "    scoring='f1_micro',          \n",
    "    max_leaf_nodes = 21,\n",
    "    l2_regularization = 0.1,\n",
    ")\n",
    "\n",
    "hist_model.fit(X, y)\n",
    "print(f\"HistGradientBoosting Model: F1 Score (Micro-Average) = {f1_score(y, hist_model.predict(X), average='micro') * 100:.2f}%\")\n",
    "\n",
    "sample_submission = pd.read_csv(r\"/kaggle/input/playground-series-s3e22/sample_submission.csv\")\n",
    "submission = hist_model.predict(test_df)\n",
    "sample_submission['outcome'] = submission\n",
    "sample_submission\n",
    "\n",
    "sub = hist_model.predict(new_df)\n",
    "list_pred = hist_model.predict(data_list)\n",
    "sub[0]\n",
    "\n",
    "outcome_mapping = {0.0: 'died', 1.0: 'euthanized', 2.0: 'lived'}\n",
    "\n",
    "# Map the values in the \"outcome\" column using the dictionary\n",
    "sample_submission['outcome'] = sample_submission['outcome'].map(outcome_mapping)\n",
    "sample_submission\n",
    "\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6536030,
     "sourceId": 59110,
     "sourceType": "competition"
    },
    {
     "datasetId": 3802992,
     "sourceId": 6588553,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.614386,
   "end_time": "2024-04-15T19:16:49.750183",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-15T19:16:33.135797",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
